---
title: "Human Actibity Recognition  model"
subtitle: "Practical Machine Learning, course project"
author: "Michael Mikhailidi"
date: "April 25, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)

require(caret);require(knitr)
require(ggplot2);require(ipred)
require(randomForest);require(margin)
require(e1071);require(foreach)

```

# Summary

This paper describes implementation  of the machine learning algorithms and methods to  predict  human activity, using measurements from the wearable devices such as smartphones, smartwatches, ativity trackers and so on. 
The stududy has been done with HAR dataset, collected by the group of the researchers (please check the project page here [http://groupware.les.inf.puc-rio.br/har](http://groupware.les.inf.puc-rio.br/har).
Goal of this work to build mathmatical model, which could identify human activity using data from the wearable devices. 

# Source Data
Fo train and test prediction models we will use two data sets, generously provided by the HAR project contributors. 
Training dataset could be found at [https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv).
Testing data are located [https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv).

```{r }
# Cached file names
trnFile="./dataCache/pml-training.csv";
tstFile="./dataCache/pml-testing.csv";
# check if files are  available
if (!file.exists(trnFile)) 
   download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",trnFile,method="auto");
if (!file.exists(tstFile)) 
     download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",tstFile,method="auto");
```
Let's take a look into the source file. 

"19621","adelmo",1322832937,964299,"02/12/2011 13:35","no",864,143,-35.9,131,18,"","","","","","",NA,NA,"",NA,NA,"",NA,NA,"",NA,NA,NA,NA,NA,NA,NA,NA,NA,NA,0.37,.....,"E"
"19622","adelmo",1322832937,972293,"02/12/2011 13:35","yes",864,143,-36,132,18,"-1.175902","-1.063259","#DIV/0!","0.196860",......,"E"

As you may see, there are plenty non-numeric values, like *NA* or *#DIV/0!*, those values may turn varable fro mthe inear to the factor, so we will instruct read.csv to handle them properly.

```{r getData}
# Load testing and training data sets.
training<- read.csv(trnFile,header = TRUE, na.strings = c("NA","NaN","#DIV/0!"));
testing <- read.csv(trnFile,header =TRUE, na.strings = c("NA","NaN","#DIV/0!"));
```
# Preprocess  data

We will use _training_ data for preparation and mode training, while  _testing_  data set will be used only for the model verification. Let's take a look to the dataset and  structure of the training data. 
```{r dataObservation}
# Ensure reproducable results.
set.seed(70720791)
dim(training);
str(training,list.len=10)
```

We have 159 variable, and after closer look not all of them are good enough for the model. For example variable  *X* is nothing like a row number and would give us unwanted noise for the prediction. As soon as I'm going to  predict activity class using accelerometers data, I'd razer exclude all the date/time variables, as sson as they will be tightly correlated to the measurements. We lay down most of the night, didn't we? The same  true for the usernames. There are strong and unwanted corealtion because  users may have have different devices with the different variable. 

```{r NaRate}
 #Remove row numbers and misleading variables
 tr<-subset(training,select=-c(1:7))
 kable(as.data.frame(sapply(levels(training$classe),function(X){table(is.na(training[training$classe == X,]))})))

```
Table above demonstrates, that most of the measurements has no values. Because most of the prediction algorithms are not tollerant to the missing values, I prepare the training set  as follow. 
1. Drop zero or constant variables   
```{r NZV}
ztr<-nearZeroVar(tr,saveMetrics = TRUE)
head(ztr[ztr$zeroVar+ztr$nzv>0,])
tr <-tr[,-nearZeroVar(tr)]
``` 
2. Preprocess data to impute missing values and perform principal component analysis.
```{r PCA}
ppr<-preProcess(tr[,-160],method=c("bagImpute","center","pca"))
#Preprocess results
ppr
## Prepre data for prediction
trp<-predict(ppr,tr)
dim(trp)
```

#Build prediction models
It's time to build predition models. Because model should classify human activity, I have selected two classification models: 
* Random Forest (parallel version)
* Gradient Boosted Models

Training models even with the  prepared data set is time quite time consuming, so code below trains modelv only if there is noo file cache available. othervise it reads cached bidary data in .rds format. 

```{r randomForest}
# Cached model files
rfFile="./dataCache/rfFit.rds";
gbFile="./dataCache/gbmFit.rds";
# Preparing RandomForestModel 
if (file.exists(rfFile)) {
   rfFit<-readRDS(rfFile);
} else {
# Fitting parallel Random Forset model
 rfParam<-expand.grid(mtry=round(sqrt(ncol(trp))))
 rfFit<-train(classe ~ .,trp,method="parRF",tuneGrid=rfParam) 
 saveRDS(rfFit,rfFile)
}
  
if (file.exists(gbFile)) {
  gbmFit<-readRDS(gbFile);
} else {
# compute  GBM model
  gbmFit<-train(classe ~ ., trp,method="gbm", trace=FALSE);
}
```

Nowe we have two trained models. let's check models accuracy and check if  combined model would improve prediction.

```{r rfErrorRates,dpi=100,figure.width=10,figure.height=10,out.width='800px',out.height='800px'}
 plot(rfFit$finalModel,main="Random Forest model. Error rate")
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}saveRD
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
